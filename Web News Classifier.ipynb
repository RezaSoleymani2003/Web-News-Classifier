{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "#Random\n",
    "import random\n",
    "\n",
    "#CSV\n",
    "import csv  \n",
    "\n",
    "#OS\n",
    "import os\n",
    "\n",
    "# Selenium\n",
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.firefox.service import Service\n",
    "# from selenium.webdriver.support.ui import WebDriverWait\n",
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.common.exceptions import TimeoutException\n",
    "# from selenium.common.exceptions import WebDriverException\n",
    "# from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "#\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "#Seyed\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import trafilatura\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import glob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCsv(\n",
    "    type,\n",
    "    source,\n",
    "    url,\n",
    "    id,\n",
    "    topic,\n",
    "    author,\n",
    "    timeRelease,\n",
    "    vote,\n",
    "    commentsCount,\n",
    "    language,\n",
    "    token,\n",
    "    predicte,\n",
    "    rawText,\n",
    "):\n",
    "    columnTopics = [\n",
    "        \"Type\",\n",
    "        \"Source\",\n",
    "        \"URL\",\n",
    "        \"ID\",\n",
    "        \"Topic\",\n",
    "        \"Author\",\n",
    "        \"TimeRelease\",\n",
    "        \"Vote\",\n",
    "        \"CommentsCount\",\n",
    "        \"Language\",\n",
    "        \"Token\",\n",
    "        \"Predicte\",\n",
    "        \"RawText\",\n",
    "    ]\n",
    "    row = [\n",
    "        type,\n",
    "        source,\n",
    "        url,\n",
    "        id,\n",
    "        topic,\n",
    "        author,\n",
    "        timeRelease,\n",
    "        vote,\n",
    "        commentsCount,\n",
    "        language,\n",
    "        token,\n",
    "        predicte,\n",
    "        rawText\n",
    "    ]\n",
    "    \n",
    "    fileName = \"RecordsNewsReddit.csv\"\n",
    "    file_exists = os.path.exists(fileName)\n",
    "    \n",
    "    with open(fileName, mode=\"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writerow(columnTopics)\n",
    "        \n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" #Example Save Data\n",
    "saveCsv(\n",
    "    type=\"Reddit\",\n",
    "    source=\"r/news\",\n",
    "    url=\"https://reddit.com/r/news/xyz\",\n",
    "    id=\"abc123\",\n",
    "    topic=\"Breaking News\",\n",
    "    author=\"user42\",\n",
    "    timeRelease=\"2025-09-08 12:00\",\n",
    "    vote=420,\n",
    "    commentsCount=69,\n",
    "    language=\"en\",\n",
    "    token=\"breaking,news\",\n",
    "    predicte=\"Politics\"\n",
    ") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "init -> (userAgent)(no need)\n",
    "→ (login)(Optional)\n",
    "→ loop { \n",
    "     rateLimiter\n",
    "     randomDelay\n",
    "     fetch/searchSubReddit\n",
    "     cleanData(deduplication + canonicalization)\n",
    "     saveData(incremental)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "def init():\n",
    "    try:\n",
    "        user_agents = [\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:142.0) Gecko/20100101 Firefox/142.0\",\n",
    "            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 15.6; rv:142.0) Gecko/20100101 Firefox/142.0\",\n",
    "            \"Mozilla/5.0 (X11; Linux i686; rv:142.0) Gecko/20100101 Firefox/142.0\",\n",
    "            \"Mozilla/5.0 (X11; Linux x86_64; rv:142.0) Gecko/20100101 Firefox/142.0\",\n",
    "            \"Mozilla/5.0 (X11; Ubuntu; Linux i686; rv:142.0) Gecko/20100101 Firefox/142.0\"\n",
    "        ]\n",
    "        random_agent = random.choice(user_agents)\n",
    "\n",
    "        options = Options()\n",
    "        options.set_preference(\"general.useragent.override\", random_agent)\n",
    "\n",
    "        service = Service(\"/usr/bin/geckodriver\")\n",
    "        driver = webdriver.Firefox(service=service, options=options)\n",
    "        \n",
    "        print(f\"[INFO] Using User-Agent: {random_agent}\")\n",
    "        return driver\n",
    "\n",
    "    except WebDriverException as e:\n",
    "        print(\"WebDriver error happened:\", e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomDelay\n",
    "def randomDelay():\n",
    "    time.sleep(random.uniform(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(type, source, post_id, title, author, votes, comments, time_release, url):\n",
    "    \"\"\"Clean, deduplicate, canonicalize, and save post.\"\"\"\n",
    "    fileName = \"RecordsNewsReddit.csv\"\n",
    "    \n",
    "    # Canonicalize: strip strings\n",
    "    post_id = post_id.strip() if post_id else \"N/A\"\n",
    "    title = title.strip() if title else \"N/A\"\n",
    "    author = author.strip() if author else \"N/A\"\n",
    "    url = url.strip() if url else \"N/A\"\n",
    "    \n",
    "    # Convert votes/comments to int if possible\n",
    "    try:\n",
    "        votes = int(votes)\n",
    "    except:\n",
    "        votes = 0\n",
    "    try:\n",
    "        comments = int(comments)\n",
    "    except:\n",
    "        comments = 0\n",
    "    \n",
    "    # Convert time_release to standard format\n",
    "    try:\n",
    "        if time_release != \"N/A\":\n",
    "            dt = datetime.fromisoformat(time_release.replace(\"Z\", \"+00:00\"))\n",
    "            time_release = dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        else:\n",
    "            time_release = \"N/A\"\n",
    "    except:\n",
    "        time_release = \"N/A\"\n",
    "    \n",
    "    # Deduplication: check existing CSV\n",
    "    existing_ids = set()\n",
    "    if os.path.isfile(fileName):\n",
    "        with open(fileName, \"r\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                existing_ids.add(row[\"ID\"])\n",
    "    \n",
    "    if post_id in existing_ids:\n",
    "        print(f\"Duplicate found: {post_id}, skipping...\")\n",
    "        return\n",
    "    \n",
    "    # Save to CSV\n",
    "    saveCsv(\n",
    "        type=type,\n",
    "        source=source,\n",
    "        url=url,\n",
    "        id=post_id,\n",
    "        topic=title,\n",
    "        author=author,\n",
    "        timeRelease=time_release,\n",
    "        vote=votes,\n",
    "        commentsCount=comments,\n",
    "        language=\"N/A\",\n",
    "        token=\"N/A\",\n",
    "        predicte=\"N/A\",\n",
    "        rawText=\"N/A\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xpath\n",
    "\n",
    "/html/body/shreddit-app/div[3]/div/div[2]/main/div[2]/shreddit-feed/article[1]/shreddit-post/a\n",
    "\n",
    "/html/body/shreddit-app/div[3]/div/div[2]/main/div[2]/shreddit-feed/article[2]/shreddit-post/a\n",
    "\n",
    "=====================\n",
    "\n",
    "CSS Selector:\n",
    "#t3_1nc1j6c > a:nth-child(1)\n",
    "#t3_1n43yfc > a:nth-child(1)\n",
    "\n",
    "=====================\n",
    "\n",
    "[json for reddit](https://www.reddit.com/r/news/.json)\n",
    "\n",
    "-----------------------\n",
    "(https://www.reddit.com/r/news/comments/1mvlhxn/texas_cant_require_the_ten_commandments_in_every/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDataSubReddit(driver, type, source, total_posts=50, posts_before_cooldown=30, cooldown_time=60):\n",
    "    scraped = 0\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    # Track last time we saved a post\n",
    "    last_scrape_time = time.time()\n",
    "\n",
    "    while scraped < total_posts:\n",
    "        # Check if 3 minutes passed without scraping new posts\n",
    "        if time.time() - last_scrape_time > 180:\n",
    "            print(\"No new posts saved for 3 minutes. Stopping...\")\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            # Wait until at least one post is loaded\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"shreddit-post\"))\n",
    "            )\n",
    "            posts = driver.find_elements(By.CSS_SELECTOR, \"shreddit-post\")\n",
    "\n",
    "            # If next post is not loaded, scroll a bit and wait\n",
    "            if scraped >= len(posts):\n",
    "                driver.execute_script(\"window.scrollBy(0, 800);\")  # small scroll\n",
    "                time.sleep(random.uniform(1, 2))\n",
    "                continue\n",
    "\n",
    "            post = posts[scraped]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"No posts loaded yet or error: {e}\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "        # Extract attributes safely\n",
    "        post_id = post.get_attribute(\"id\") or \"N/A\"\n",
    "        permalink = post.get_attribute(\"permalink\") or \"N/A\"\n",
    "        title = post.get_attribute(\"post-title\") or \"N/A\"\n",
    "        author = post.get_attribute(\"author\") or \"N/A\"\n",
    "        votes = post.get_attribute(\"score\") or \"0\"\n",
    "        comments = post.get_attribute(\"comment-count\") or \"0\"\n",
    "        time_release = post.get_attribute(\"created-timestamp\") or \"N/A\"\n",
    "        url = post.get_attribute(\"content-href\") or \"N/A\"\n",
    "\n",
    "        # Clean, deduplicate, and save\n",
    "        cleanData(type, source, post_id, title, author, votes, comments, time_release, url)\n",
    "\n",
    "        scraped += 1\n",
    "        last_scrape_time = time.time()  # reset timer since we got a new post\n",
    "        time.sleep(random.uniform(1, 2))\n",
    "\n",
    "        # Cooldown after N posts\n",
    "        if scraped % posts_before_cooldown == 0:\n",
    "            print(f\"Cooldown: {scraped} posts scraped. Waiting {cooldown_time} sec...\")\n",
    "            time.sleep(cooldown_time)\n",
    "\n",
    "        # Scroll if at bottom of loaded content\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            driver.execute_script(\"window.scrollBy(0, 1000);\")\n",
    "            time.sleep(random.uniform(1, 2))\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        last_height = new_height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subReddits List\n",
    "subRedditsNews = [\n",
    "    \"r/news/\",\n",
    "    \"r/worldnews/\",\n",
    "    \"r/realbbcnews/\",\n",
    "    \"r/world24x7hr/\"\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fetch/searchSubReddit\n",
    "def searchRedditNews(subRedditsNews, total_posts_per_subreddit=1):\n",
    "    baseURLReddit = \"https://www.reddit.com/\"\n",
    "    driver = init()\n",
    "    for subreddit in subRedditsNews:   \n",
    "        full_url = baseURLReddit + subreddit     \n",
    "        driver.get(full_url) \n",
    "        clean_url = driver.execute_script(\"return window.location.origin + window.location.pathname\")\n",
    "        driver.get(clean_url)        \n",
    "        type = \"reddit\"\n",
    "        source = subreddit\n",
    "        randomDelay()       \n",
    "        extractDataSubReddit(driver, type, source, total_posts=total_posts_per_subreddit)\n",
    "        time.sleep(10)\n",
    "    driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchRedditNews(subRedditsNews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract text from each news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_text(url):\n",
    "    \"\"\"Fetch raw text from a URL using requests + BeautifulSoup.\"\"\"\n",
    "    # Skip image URLs\n",
    "    if any(x in url for x in [\"i.redd.it\", \"redd.it\", \"reddit\"]):\n",
    "        return \"N/A\"\n",
    "    \n",
    "    try:\n",
    "        headers = {\n",
    "            \"User-Agent\": (\n",
    "                \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                \"Chrome/116.0.0.0 Safari/537.36\"\n",
    "            )\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to fetch {url}, status code: {response.status_code}\")\n",
    "            return \"N/A\"\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        paragraphs = soup.find_all(\"p\")\n",
    "        raw_text = \"\\n\".join(p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True))\n",
    "        if not raw_text:\n",
    "            return \"N/A\"\n",
    "        return raw_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return \"N/A\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeRawTextFromCSV(csv_file=\"RecordsNewsReddit.csv\"):\n",
    "    \"\"\"Scrape RawText from URLs in a CSV using requests + BeautifulSoup.\"\"\"\n",
    "    if not os.path.isfile(csv_file):\n",
    "        print(f\"CSV file {csv_file} not found.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_file, keep_default_na=False)\n",
    "\n",
    "    # Create RawText column if it doesn't exist\n",
    "    if \"RawText\" not in df.columns:\n",
    "        df[\"RawText\"] = \"\"\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        if str(row.get(\"Type\", \"\")).lower() != \"reddit\":\n",
    "            continue\n",
    "\n",
    "        raw_text_val = str(row.get(\"RawText\", \"\"))\n",
    "        if raw_text_val.strip() not in [\"\", \"N/A\"]:\n",
    "            # Already scraped\n",
    "            continue\n",
    "\n",
    "        url = row.get(\"URL\", \"\")\n",
    "        if not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "            print(f\"Skipping invalid URL: {url}\")\n",
    "            df.at[idx, \"RawText\"] = \"N/A\"\n",
    "            continue\n",
    "\n",
    "        print(f\"Scraping raw text from: {url}\")\n",
    "        raw_text = get_raw_text(url)\n",
    "        df.at[idx, \"RawText\"] = raw_text\n",
    "\n",
    "        # Small delay to avoid overloading servers    \n",
    "        # Save updated CSV\n",
    "        df.to_csv(csv_file, index=False, encoding=\"utf-8\") \n",
    "        print(f\"we are saving {row.get('ID','')}.\")   \n",
    "        time.sleep(1)\n",
    "        \n",
    "    print(f\"CSV updated in-place: {csv_file}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapeRawTextFromCSV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi Process For RedditScrap\n",
    "Mult Thread For News Crawl Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(sublist, total_posts_per_subreddit=300):\n",
    "        searchRedditNews(sublist, total_posts_per_subreddit=total_posts_per_subreddit)\n",
    "\n",
    "def multiProcessReddit(subRedditsNews):\n",
    "    mid = len(subRedditsNews) // 2\n",
    "    half1 = subRedditsNews[:mid]\n",
    "    half2 = subRedditsNews[mid:]\n",
    "\n",
    "    p1 = Process(target=worker, args=(half1,))\n",
    "    p2 = Process(target=worker, args=(half2,))\n",
    "\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    print(\"All subreddits scraped!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiProcessReddit(subRedditsNews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_row(idx, row, csv_file):\n",
    "    if str(row.get(\"Type\", \"\")).lower() != \"reddit\":\n",
    "        return None, None\n",
    "\n",
    "    raw_text_val = str(row.get(\"RawText\", \"\"))\n",
    "    if raw_text_val.strip() not in [\"\", \"N/A\"]:\n",
    "        return idx, raw_text_val  # already scraped\n",
    "\n",
    "    url = row.get(\"URL\", \"\")\n",
    "    if not isinstance(url, str) or not url.startswith(\"http\"):\n",
    "        print(f\"Skipping invalid URL: {url}\")\n",
    "        return idx, \"N/A\"\n",
    "\n",
    "    print(f\"Scraping raw text from: {url}\")\n",
    "    raw_text = get_raw_text(url)\n",
    "    time.sleep(1)  # avoid hitting server too fast\n",
    "    return idx, raw_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeRawTextFromCSV_multithreaded(csv_file=\"RecordsNewsReddit.csv\", max_workers=5):\n",
    "    if not os.path.isfile(csv_file):\n",
    "        print(f\"CSV file {csv_file} not found.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(csv_file, keep_default_na=False)\n",
    "    if \"RawText\" not in df.columns:\n",
    "        df[\"RawText\"] = \"\"\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(scrape_row, idx, row, csv_file) for idx, row in df.iterrows()]\n",
    "\n",
    "        for future in futures:\n",
    "            idx, raw_text = future.result()\n",
    "            if idx is not None:\n",
    "                df.at[idx, \"RawText\"] = raw_text\n",
    "                # save incrementally\n",
    "                df.to_csv(csv_file, index=False, encoding=\"utf-8\")\n",
    "                print(f\"Saved {df.at[idx, 'ID']}\")\n",
    "\n",
    "    print(f\"CSV updated in-place: {csv_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapeRawTextFromCSV_multithreaded(csv_file=\"RecordsNewsReddit.csv\", max_workers=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_seeds = [\n",
    "    \"https://www.theguardian.com/world\", # 54\n",
    "    \"https://www.aljazeera.com/news/\", # 19\n",
    "    \"https://www.nytimes.com/section/world\",# forbidden url\n",
    "    \"https://www.nbcnews.com/world\",# keyword: world , 22\n",
    "]\n",
    "\n",
    "visited = set()\n",
    "articles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visited = set()\n",
    "articles = []\n",
    "\n",
    "def canonicalize(url):\n",
    "    \"\"\"Remove fragments and query params from URL.\"\"\"\n",
    "    parsed = urlparse(url)\n",
    "    # (scheme, netloc, path, params, query, fragment)\n",
    "    return urlunparse((parsed.scheme, parsed.netloc, parsed.path, \"\", \"\", \"\"))\n",
    "\n",
    "\n",
    "def extract_text(html, url):\n",
    "    \"\"\"Try to extract main article text using trafilatura, fallback to <p> tags.\"\"\"\n",
    "    text = trafilatura.extract(html, url=url)\n",
    "    if text:\n",
    "        return text\n",
    "    else:\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        return \" \".join([p.get_text() for p in soup.find_all(\"p\")])\n",
    "\n",
    "def crawl(url, index, depth=1):\n",
    "    url = canonicalize(url)\n",
    "\n",
    "    if depth == 0 or url in visited:\n",
    "        return\n",
    "    \n",
    "    if True:\n",
    "        print(f\"Crawling: {url}\")\n",
    "        visited.add(url)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            response.raise_for_status()\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {url}: {e}\")\n",
    "            return\n",
    "        \n",
    "        html = response.text\n",
    "        \n",
    "        text = extract_text(html, url)\n",
    "        \n",
    "        if text:\n",
    "            if re.search(r\"/20\\d{2}/\", url):  \n",
    "                articles.append({\"url\": url, \"id\": 0, \"title\": 0, \"writer\": 0,  \"raw_text\": text})\n",
    "                print(f\"Saved article ({len(text)} chars)\")\n",
    "        else:\n",
    "            print(f\"Not an article, but checking links...\")\n",
    "        \n",
    "        # Parse links\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        for link in soup.find_all(\"a\", href=True):\n",
    "            new_url = urljoin(url, link[\"href\"])\n",
    "            \n",
    "            # Filter: must be within same domain as seed\n",
    "            if new_url not in visited and url.split(\"/\")[2] in new_url:\n",
    "                crawl(new_url, index, depth - 1)\n",
    "\n",
    "\n",
    "# crawl(news_seeds[0], 0, depth=3)\n",
    "# print(f\"Collected {len(articles)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(articles[310]['raw_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(articles, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored 537 articles\n",
      "When a history of resistance to the lurching authoritarianism of Donald Trump’s second presidency is written, it could well begin on 11 April 2025, inside a small immigration courtroom in remote, central Louisiana.\n",
      "It was there, in the early afternoon, that a slight young man dressed in a blue uniform jumpsuit spoke calmly but directly to the new administration – away from the gaze of television cameras and 1,000 miles (1,610km) from his friends and family. Mahmoud Khalil, the Columbia University graduate and Palestinian organiser, had been arrested a month earlier – snatched from the lobby of his Manhattan apartment building as he returned home with his wife. Now, detained in the small town of Jena, he sat before a judge who had just ruled that he was eligible to be deported from the United States purely for his political views.\n",
      "Khalil asked for permission to speak. He paused for a moment, before sharply rebuking the jurist who continued to hold his fate in her hands by throwing her own words back at her. He reminded her that she had guaranteed that the court would ensure him “due process” and “fundamental fairness”.\n",
      "“Neither of these principles were present today or in this whole process,” he told her, in effect branding the venue a kangaroo court. “This is exactly why the Trump administration has sent me to this court, 1,000 miles away from my family.”\n",
      "I was one of a handful of journalists in Jena that day. It was a period of particular distress in the US, his arrest being the first of a spate of high-profile detentions of students seized off the streets by immigration agents over their political views. In that moment of fear, when so many were going silent, I was taken aback by the quiet courage that seemed to come so naturally to Khalil even as formal political opposition to Trump’s iron fist had largely faltered.\n",
      "Four months on, and now bailed from detention and back in New York, I ask Khalil where it had come from and whether he would define it as an act of bravery.\n",
      "“No. I have always believed in standing up against injustice,” he says in his gentle voice. “I knew that it was predetermined. That it was a play. It was theatre. I did not want to play within their rules.”\n",
      "On a bright summer’s day in Brooklyn, Khalil invites me to his new apartment that commands a towering view over the borough’s low-rises. The walls are freshly painted white – he had moved in just a few weeks earlier – and we sit on a grey sofa by the window. His four-month-old son, Deen, is crying softly in the next room as Noor Abdalla, his wife, soothes him.\n",
      "It is an archetypal scene of a young New York family: a baby rocker sits beside a large TV, white tulips lean against a ceramic vase, bright artwork adorns the walls. Khalil is warm and candid, he offers me chocolate and water before we start talking. But the grim reality of his situation soon lingers as we dial an attorney from his legal team who listens in to our three-hour conversation as a precaution.\n",
      "Although he is free from detention, the Trump administration’s case against him is still winding through the courts. While he is a legal permanent resident, he acknowledges deportation could still be the ultimate outcome.\n",
      "“This administration is trying to do everything in its power – and beyond its power, in fact – to punish me and deport me,” he says. “Up until very recently, they were trying to rearrest me.”\n",
      "He is working on contingency plans for if and when that happens, he acknowledges, without describing specifics. For now, he has attempted to return to a degree of normality. He spends his days with baby Deen, learning to be a father after he missed the birth while detained. He recently rode the subway for the first time since his release, but still finds himself looking over his shoulder. The move to Brooklyn was partly to create distance from Columbia’s campus and all the past wounds of its recent history. But still, it remains difficult to focus.\n",
      "A Palestinian refugee, intimately familiar with the experience of repeated displacement, he remains resolute in the face of a prospective fresh exile.\n",
      "“Even if I am deported, I would continue to speak out for Palestine,” he says.\n",
      "Khalil’s life was changed forever when agents in plainclothes came to his old apartment back in March. His arrest, captured on video by Abdalla, marked a turning point as Trump ramped up his era of mass deportations and began a censorship campaign against the campuses that saw large protests of Israel’s war in Gaza. Khalil remained calm as he was placed in handcuffs and driven away, with his wife – heavily pregnant – left on the sidewalk, desperately calling their lawyer.\n",
      "I wonder if he has ever watched the video back?\n",
      "He shakes his head.\n",
      "“It is a moment I would never want to remember,” he says. “It was one of the most difficult, scariest moments in my life. I do not want to watch a moment where I was helpless to support Noor.”\n",
      "His overwhelming memory of that night is his fear that Abdalla, a US citizen, might also face arrest. He repeated her phone number in his head so as not to forget it. But he also remembers making “chill” small talk with the arresting agents as he was driven away. They spoke about the iftar dinner, the breaking-fast meal taken during Ramadan, he had just eaten.\n",
      "“I did not fear them whatsoever,” he recalls. “I saw them eye to eye.”\n",
      "Shortly after the arrest, he overheard an incoming phone call from the White House, requesting an update. He was then presented with a document that accused him of no crime, but argued his presence in the US compromised foreign policy interests. (A memo signed by US secretary of state Marco Rubio, disclosed later, argued this was due to participation in “antisemitic protests and disruptive activities”.)\n",
      "He read it and laughed in disbelief.\n",
      "“Are they really going this far in coming after me?” he thought.\n",
      "After 36 hours of travel under guard, he ended up in Jena, the sprawling centre four hours from New Orleans, hidden away in a pine forest by a country road. It is known as one of the harshest immigration jails in the US. Inside his large detention dormitory, the TV was blaring and he saw Trump at a press conference on the White House lawn perusing Teslas with Elon Musk.\n",
      "The president was asked about Khalil’s arrest.\n",
      "“We ought to get him the hell out of the country,” Trump replied.\n",
      "It was at this point he started to realise the enormity of it all – a public narrative about him spiralling out of his control, laundered through a vast rightwing disinformation infrastructure branding him an antisemite and terrorism supporter.\n",
      "“Who I am has been skewed so much,” he recalls thinking. “I was like: ‘Damn my future is basically done … my reputation, my career aspirations.’”\n",
      "But through the horror, he says he knew his record would ultimately speak for itself. “That was my salvation,” he says. “I was 100% confident I had a very clean history. They would be able to get no dirt on me.”\n",
      "He spoke to Abdalla by phone. She was safe. She told him about an outpouring of support across the world. He sighed with relief.\n",
      "That quiet courage, which Khalil has carried throughout this ordeal, has been forged since childhood, at the multiple junctures he was forced to upend his life.\n",
      "He was born in a small Palestinian refugee camp named Khan Eshieh on the outskirts of Damascus, the youngest of four brothers. His paternal grandparents were displaced from their farmland outside of Tiberias, in what is now Israel, during the Nakba of 1948. His father was a welder who left school at the age of 10. His mother, a low-level civil servant, ended her education at 16.\n",
      "His Palestinian identity was omnipresent growing up; most of his neighbours were displaced from the same region as his grandparents. And his grandmother, who was illiterate, would tell stories of her life in Palestine, always with a view to eventual return.\n",
      "“You could see the struggle in her face,” he says.\n",
      "His parents, both largely apolitical, instilled in him the values of a formal education and he excelled, graduating with aspirations to become a commercial pilot. But the forces of history had other plans. The final few years of his schooling in Syria coincided with the pro-democracy movements that swept across the region during the Arab spring. One of his first forays into formal activism came on 15 May 2011, as part of a series of “Nakba Day” demonstrations at Israel’s borders. At least a dozen protesters were killed during the clashes with Israeli forces. Dozens more were injured.\n",
      "Khalil was one of them. Aged 16, he was shot in the leg and spent a number of days in hospital. “That was the first real encounter of violence, direct violence, by Israel against me,” he says.\n",
      "The experience propelled him further into the tumultuous politics of the era – initially heady and full of promise before quickly deteriorating into state brutality and civil war. He witnessed the crackdowns of the Assad regime on close friends and family who helped provide shelter to Syrians fleeing Damascus. Khalil became involved in organising smaller acts of resistance: street protests, spray painting and posting anti-Assad comments on social media.\n",
      "“These things were the very minimum we could do,” he says. “In a time where you know that injustices are happening around you, staying silent is complicity. Pure complicity.”\n",
      "It all intensified after graduating high school. He had been set to study aerospace engineering at the University of Aleppo, but the city was burning as the civil war raged. On 11 January 2013, a week after he turned 18, two of his childhood friends and co-organisers named Bashar and Ali were snatched off the street by Syrian intelligence officers. He feared he would be next.\n",
      "The same night he made plans to flee, crossing the border into Lebanon the next day. “I left everything behind,” he says. “I fled without a plan. My biggest worry was that they would confess the names of the people around them. And you wouldn’t blame them to confess under such torture by the regime.”\n",
      "Bashar and Ali were murdered after their arrest, their deaths confirmed only a few months ago after the Assad regime collapsed at the end of 2024.\n",
      "Khalil recognises the different shades of authoritarianism he has faced throughout his life.\n",
      "“What shocked me at the very beginning, when I was kidnapped [by US immigration], was just how reminiscent that was to cases I witnessed in Syria,” he says. “You would have plainclothed officers without any warrant come and take you just because of your political speech.”\n",
      "Khalil languished in Jena for more than 100 days. He had known little about the US’s deportation machine, and the detention center’s reputation as a legal black hole, until he experienced it all.\n",
      "He slept in a large dorm room lined with bunkbeds, holding about 70 men. He spent time dictating well-written dispatches over the phone to his legal team. He read literature: Out of Place, the autobiography of the Palestinian academic Edward Said; Man’s Search for Meaning, the psychologist Viktor Frankl’s memoir of surviving the Holocaust. But mostly he shared stories with the other men detained with him. Many had been picked up during routine check-ins with immigration officials. Others were recently apprehended at the southern border. A few had been detained in Jena for more than a year. The majority of people who pass through immigration court in Jena have no lawyers as mandatory legal representation is not guaranteed.\n",
      "One man, a Georgian national, had been held for about eight months, picked up with his wife in California. Held in separate detention centres about two hours apart, the couple, who were fleeing Georgia’s new pro-Russia government, had not been able to speak to each other since their arrest. The man, a carpenter, spent hours fashioning improvised rosaries from commissary items, including crayon, ground coffee and bread – hardened into beads by heat in a microwave. Khalil shows me a set, still impressed by the ingenuity.\n",
      "Many of the men, Khalil says, have since been removed from the US.\n",
      "For Khalil, the lowest moment came on the night his son was born. His requests for a furlough to attend the birth were denied and so he was forced to listen on the phone in the middle of the night, whispering quiet words of encouragement as Abdalla laboured. The line cut around 2am, and by the time he called back he heard his newborn son crying in the background. He whispered the call to prayer down the line to welcome baby Deen into the world.\n",
      "“It was a very difficult moment that I don’t wish anyone to go through,” he says, his eyes drifting. “It was a clear act of cruelty just to punish me.”\n",
      "Abdalla emerges to say hello with Deen in her arms. Khalil’s face lights up. At four months, his son has a full head of hair, deep dimples and expressive brown eyes that follow his father around the room.\n",
      "I ask her how it feels to have her husband back.\n",
      "“Not having him for the first two months of Deen’s life was hard,” she says. “We missed a lot of milestones that you can’t get back. So we are catching up on lost time.”\n",
      "The new apartment is their “safe space”, she says. The couple have been largely welcomed with open arms here, receiving spontaneous acts of kindness: an unexpected free lunch, smiles on the street. I am the first journalist they have invited over.\n",
      "Khalil met his future wife, now a dentist, in Lebanon in 2016, while working for a non-profit helping educate Syrian refugees. She visited on an exchange program. He had worked his way up from nothing after fleeing Syria, taking construction jobs during the day and volunteering for a refugee charity in the evenings, which granted him free room and board in their office. Eventually he attended university to study computer science and took remedial English classes. He gradually let go of his dream to fly commercial jets, becoming more immersed in the work of government and bureaucracy.\n",
      "Khalil and Abdalla bonded over games of backgammon and stayed in touch after she returned home to Flint, Michigan. He was attracted to her kindness and gentle nature. She found his intellect and ambition appealing, and eventually pushed him to apply for a job at the British embassy, where he worked on Syria policy until moving to New York in 2023. Their long-distance relationship lasted seven years.\n",
      "I ask how fatherhood has changed him since he returned home.\n",
      "“It absolutely makes me think [more] about risks,” he acknowledges. “When you have someone depending on you, you want them to have as normal a life as possible. But at the same time it pushes me towards advocacy. When I see Deen I always remember the children who are being killed because of Israel, who don’t have the luxury of being in New York. [I think of] immigrant children who don’t have the luxury of having an American passport that would somehow protect them.”\n",
      "But Palestinian liberation is never far from his imagination.\n",
      "“I want Deen to be able to visit his home town, his ancestors’ town, and live equally with everyone,” he says.\n",
      "The pro-Gaza protests at Columbia marked the first time Khalil had ever assumed a public-facing role. Having set his sights on a behind-the-scenes job in government bureaucracy, he was instead thrust into a spring of campus tumult in 2024 as students constructed encampments, staged rallies and, in late April, occupied the university’s Hamilton Hall, leading to an overwhelming police response.\n",
      "Khalil served as a negotiator with the university’s administration, presenting students’ demands, including divestment from companies with ties to Israel. He was not present on campus during the Hamilton Hall occupation.\n",
      "The negotiations were protracted but civil. A Columbia administrator, anonymously quoted in the New York Times, later described Khalil as “thoughtful, passionate, and principled, sometimes to the point of rigidity”. It strikes me as apt, but I wonder if he agrees?\n",
      "“Pretty much,” he says, smiling. “I don’t know about rigidity though, because it was not my position, it was the students’.”\n",
      "Unlike many of those on the protest frontlines, Khalil did not wear a face mask, leaving him vulnerable to online doxing from hardline pro-Israel groups, which have supplied the Trump administration with lists of candidates for deportation.\n",
      "“I have never worn a mask during a protest because I knew that the purpose of doxing was to intimidate us, to silence us,” he says. But the campaign ramped up again after the election of Trump, shortly before Khalil’s arrest. He had not foreseen how dangerous it might become.\n",
      "The allegations of antisemitism have never been substantiated with hard evidence. Khalil says Jewish students played an “integral” role in organising the campus protests and argues it is Israel and the Trump administration’s policies that fuel global antisemitism through their policies.\n",
      "So how does he visualise a free Palestine?\n",
      "“I imagine it as a place where everyone lives in dignity, freedom, equality, regardless of who they are, where they come from,” he says. “I don’t think there’s an alternative to that, to have a lasting and just peace in the Middle East.\n",
      "“Liberation doesn’t mean throwing anyone out. Liberation means liberating everyone, whether the oppressed or the oppressors.”\n",
      "Khalil remains scathing of Columbia’s response to the protests and its later capitulation to the Trump administration’s demands it suppress pro-Palestinian protest. Yet he expresses an honest sadness that he was unable to walk the stage to collect his master’s degree in May this year. He is the first in his family to graduate from university. His parents had planned to travel from Germany, where they now live, to witness it. He had bought his gown a year in advance.\n",
      "“I know it would have been an incredibly important moment for my parents, who have fought and sacrificed so much for me to get to this point,” he says. Instead, he received the accolade as an emailed PDF file.\n",
      "It was late June when Khalil emerged from Jena on a sweltering humid afternoon. He raised his fist in the air to celebrate and walked towards a small group of journalists. He had lost about 15lbs (6.8kg). A federal judge in New Jersey had just ordered his release, having found the Trump administration’s foreign policy argument was likely unconstitutional.\n",
      "I had asked him that day to respond in his own words to the “threat” label that Trump had branded him with. “Trump and his administration, they chose the wrong person for this,” he told me.\n",
      "I had not fully comprehended what he meant by “the wrong person” at the time. But as our conversation comes to a close, it becomes clear. The adversity that Khalil has faced – from displacement to detention – in such a short span of life has only fuelled his sense of mission. He will not be forced into submission or silence. He views his past and future as inextricable from the wider Palestinian struggle stretching from 1948 to the current slaughter in Gaza. “It is a drop in the sea of Palestinian sorrow and grief, where families are being erased, children are being killed, houses being raided and dignity is eroded,” he says.\n",
      "He takes a moment before we wrap up, seemingly a little exhausted.\n",
      "“My story is just a small story,” he says. “A story of how violence against Palestinians can be transported around the world.”\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "with open(\"articles.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    articles = json.load(f)\n",
    "\n",
    "print(f\"Restored {len(articles)} articles\")\n",
    "print(articles[0][\"raw_text\"])  # check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"reuters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(articles):\n",
    "    for article in articles:\n",
    "        text = article['raw_text']\n",
    "        text = text.lower()\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "        # Remove special characters (keep only words and numbers)\n",
    "        text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "\n",
    "        article['normalize_text'] = text\n",
    "\n",
    "# normalize(articles)\n",
    "# print(articles[10]['normalize_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(articles):\n",
    "    for article in articles:\n",
    "        tokens = nltk.word_tokenize(article['normalize_text'])\n",
    "    \n",
    "        # Remove stopwords\n",
    "        article[\"tokens\"] = [t for t in tokens if t not in stop_words] \n",
    "\n",
    "# tokenize(articles)\n",
    "# print(articles[10]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(articles):\n",
    "    for article in articles:\n",
    "        article[\"tokens\"] = [stemmer.stem(t) for t in article[\"tokens\"]]\n",
    "\n",
    "# stem(articles)\n",
    "# print(articles[10]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(articles):\n",
    "    for article in articles:\n",
    "        article[\"tokens\"] = [lemmatizer.lemmatize(t) for t in article[\"tokens\"]]\n",
    "\n",
    "# lemmatize(articles)\n",
    "# print(articles[10]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(articles):\n",
    "    normalize(articles)\n",
    "    tokenize(articles)\n",
    "    stem(articles)\n",
    "    # lemmatize(articles)\n",
    "    \n",
    "preprocess(articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./dataset\"\n",
    "dataset_articles = []\n",
    "\n",
    "# for filename in os.listdir(DATA_DIR):\n",
    "#     if not filename.endswith(\".sgm\"):\n",
    "#         continue\n",
    "    \n",
    "#     with open(os.path.join(DATA_DIR, filename), \"r\", encoding=\"latin-1\") as f:\n",
    "#         data = f.read()\n",
    "#         soup = BeautifulSoup(data, \"html.parser\")\n",
    "        \n",
    "#         for reuters in soup.find_all(\"reuters\"):\n",
    "#             text = \"\"\n",
    "#             if reuters.body:\n",
    "#                 text = reuters.body.get_text(strip=True)\n",
    "#             topics = [t.get_text() for t in reuters.topics.find_all(\"d\")] if reuters.topics else []\n",
    "            \n",
    "#             if text.strip():\n",
    "#                 dataset_articles.append({\n",
    "#                     \"id\": reuters[\"newid\"],\n",
    "#                     \"title\": reuters.title.get_text(strip=True) if reuters.title else None,\n",
    "#                     \"raw_text\": text,\n",
    "#                     \"topics\": topics\n",
    "#                 })\n",
    "\n",
    "# print(dataset_articles[10][\"raw_text\"])\n",
    "# print(dataset_articles[10][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw_text': 'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.', 'label': 'rec.autos'}\n",
      "11314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# load training set\n",
    "data = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# build dataset_articles\n",
    "dataset_articles = []\n",
    "for text, target in zip(data.data, data.target):\n",
    "    dataset_articles.append({\n",
    "        \"raw_text\": text,\n",
    "        \"label\": data.target_names[target]\n",
    "    })\n",
    "\n",
    "print(dataset_articles[0])\n",
    "print(len(dataset_articles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# load AG News dataset\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "dataset_articles = []\n",
    "label_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
    "\n",
    "for article in dataset[\"train\"]:\n",
    "    dataset_articles.append({\n",
    "        \"raw_text\": article[\"text\"],\n",
    "        \"label\": label_names[article[\"label\"]]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_articles = dataset_articles[:1000]\n",
    "preprocess(dataset_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "X_reuters = vectorizer.fit_transform([\" \".join(dataset_article[\"tokens\"]) for dataset_article in dataset_articles])\n",
    "X_crawled = vectorizer.transform([\" \".join(article[\"tokens\"]) for article in articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_vocab = {}\n",
    "\n",
    "# Only keep articles with at least one topic\n",
    "valid_articles = [art for art in dataset_articles if art[\"label\"]]\n",
    "\n",
    "# collect unique labels (using the first topic as representative)\n",
    "labels = list(set(art[\"label\"] for art in valid_articles))\n",
    "\n",
    "for label in labels:\n",
    "    # find indices of docs belonging to this label\n",
    "    idx = [i for i, art in enumerate(valid_articles) if art[\"label\"] == label]\n",
    "    \n",
    "    if not idx:  # skip if no documents\n",
    "        continue\n",
    "    \n",
    "    # average TF-IDF weights for this category\n",
    "    avg_weights = np.asarray(X_reuters[idx].mean(axis=0)).ravel()\n",
    "    \n",
    "    # get indices of top 50 highest-weighted terms\n",
    "    top_idx = avg_weights.argsort()[::-1][:100]\n",
    "    \n",
    "    # get actual term strings\n",
    "    terms = vectorizer.get_feature_names_out()[top_idx]\n",
    "    \n",
    "    # get their corresponding weights\n",
    "    weights = avg_weights[top_idx]\n",
    "    \n",
    "    # save into dictionary\n",
    "    category_vocab[label] = dict(zip(terms, weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_article(article_vector):\n",
    "    scores = {}\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    vec_array = article_vector.toarray().ravel()\n",
    "    for label, vocab in category_vocab.items():\n",
    "        score = sum(vec_array[feature_names.tolist().index(term)] * w\n",
    "                    for term, w in vocab.items() if term in feature_names)\n",
    "        scores[label] = score\n",
    "    return scores\n",
    "\n",
    "for article, x in zip(articles, X_crawled):\n",
    "    scores = score_article(x)  # returns a dict of {label: score}\n",
    "    article[\"scores\"] = scores\n",
    "    article[\"predicted\"] = max(scores, key=scores.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'talk.politics.misc': 145, 'soc.religion.christian': 93, 'talk.politics.mideast': 67, 'rec.sport.hockey': 67, 'sci.crypt': 47, 'talk.politics.guns': 29, 'rec.sport.baseball': 28, 'misc.forsale': 13, 'sci.med': 12, 'rec.autos': 11, 'sci.space': 8, 'rec.motorcycles': 4, 'alt.atheism': 3, 'comp.graphics': 3, 'sci.electronics': 2, 'comp.windows.x': 2, 'talk.religion.misc': 1, 'comp.os.ms-windows.misc': 1, 'comp.sys.mac.hardware': 1})\n"
     ]
    }
   ],
   "source": [
    "articles[10][\"predicted\"]\n",
    "print(Counter(a[\"predicted\"] for a in articles))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the dust finally settles in the days after Sunday’s eagerly awaited US Open men’s final, the United States Tennis Association will issue its annual victory-lap press release. It will tout another record-setting Open: more than a million fans through the gates, unprecedented social-media engagement, double-digit growth in food and beverage sales, and hundreds of celebrities packed into suites from Rolex to Ralph Lauren. It will beam about growing the game, championing diversity and turning Flushing Meadows into a pop-culture destination.\n",
      "But for all the milestones the USTA is teeing up to celebrate, this year’s tournament will be remembered for a different kind of first: the governing body’s lamentable decision to ask broadcasters not to show dissent against Donald Trump. In making that pre-emptive concession, the USTA has committed an unforced error that can’t be undone: sacrificing credibility in order to shield a politician – any politician, regardless of party, ideology or affiliation – from the sound of public disapproval.\n",
      "According to internal emails obtained by outlets including PA and Bounces, the USTA instructed its television partners to “refrain from showcasing any disruptions or reactions” when Trump appears on screen during Sunday’s final. A separate note reminded staff he would be seated in Rolex’s suite as a client guest. The 11-word statement to the Guardian on Saturday night from a USTA spokesperson – “We regularly ask our broadcasters to refrain from showcasing off-court disruptions” – is so weak it could buckle under the weight of its own hypocrisy. (Rolex did not respond to a request for comment.)\n",
      "This is, after all, the same tournament that happily televised a climate protester gluing himself to a seat for nearly an hour during Coco Gauff’s semi-final win over Karolina Muchova two years ago, along with countless other fan disturbances. The same tournament that shrugs at the drunken buffoonery behind its US Bro-pen reputation. The Open practically invented televising distractions. Chaos is its brand. For the USTA to draw the line at showing boos for a sitting president is not “policy consistency” but capitulation.\n",
      "And to what end? Because of the fear that Trump – once a fixture at the US Open but loudly booed on his last visit in 2015, three months after announcing his first presidential campaign – may once again be exposed as unpopular before a global audience? Because of the fear that a chorus of jeers could overshadow the match itself? But that fear misunderstands both sport and democracy.\n",
      "Crowd dissent on broadcasts is not a breakdown of civic order. It is its expression. Then UK home secretary Theresa May was booed at the 2012 London Paralympics. French president Emmanuel Macron was whistled during the 2023 Rugby World Cup opening ceremony in Paris. In the US, NFL commissioner Roger Goodell is all but guaranteed a chorus of boos during public appearances, and that’s practically a standing ovation next to the venom reserved for NHL commissioner Gary Bettman from fans. And Trump and his predecessor, Joe Biden, have been given hostile receptions by sports crowds. Somehow the United Kingdom, France and the United States survived those incidents intact.\n",
      "That the USTA thinks Trump must be insulated from reality hints at something darker. It is reminiscent of regimes where the leader’s image must be protected from public ridicule. It shows how much Trump’s first term – and his bullying of cultural institutions – still shapes behavior. In his first presidency, he was broadly reviled by athletes and sports bodies. Now, as Tom Dart wrote before this year’s Super Bowl, he is increasingly accommodated or treated with silence.\n",
      "The Open is supposed to be New York’s tournament, brash and democratic, rowdy and unfiltered, vibrant and exuberantly multicultural, where the crowd is as much a presence as the players on the court. By sanitizing its reaction, the USTA isn’t just shielding Trump. It is stripping the event of its unique character, authenticity and integrity.\n",
      "That irony cuts even deeper because the Open has always been at the forefront of progress. It was the first of the majors to award equal prize money to women and men, long before other sports caught up. It platformed, embraced and celebrated LGBTQ+ athletes decades before it was fashionable to do so, from Billie Jean King and Martina Navratilova in the 1970s to Renée Richards breaking ground as one of the first transgender athletes in professional tennis, to Open Pride nights today. And this year’s theme, “75 years of breaking barriers”, honors Althea Gibson, who in 1950 became the first Black player to compete at the tournament’s predecessor, the US nationals, and went on to clear a path for generations of Black players who followed. Her story is literally built into the grounds this fortnight, from the banners and installations designed by Melissa Koby – the first Black artist to create the Open’s theme art – to the constant reminders that the sport has prided itself on inclusion.\n",
      "From a Maga vantage point, of course, it probably looks like the Woke Super Bowl: King’s name on the gates, Gibson’s silhouette over Ashe Stadium, Serena and Venus Williams lionized, rainbow-tinged Pride nights, and a governing body trumpeting diversity at every turn. Which, if we’re being honest, may be one reason Trump is showing up in the first place: a 4D chess move with the intent of turning a tennis match into another battleground of grievance. Getting booed by thousands of fans drinking $23 vodka-lemonades won’t exactly be a bad look for his base, especially in a corrupt, disgusting hellhole like New York.\n",
      "Fans will still do what fans do. If they want to boo, they will boo. But millions at home may never see it, thanks to a governing body that has chosen to act less like a guardian of sport and more like a nervous producer of campaign stagecraft. For a sport that prides itself on honesty and clarity – the ball is in or out – it is a shameful retreat.\n",
      "### predicted class: rec.sport.hockey\n",
      "********************\n",
      "Every August, the US Open rolls into Queens with its ever-expanding rituals of consumption. Fans don’t just buy in, they perform it: the $23 Honey Deuce held aloft for Instagram, the $40 lobster roll posted before the first serve, the $100 caviar-topped chicken nuggets bought as much for the flex as the flavor. The tennis has never been the cheapest day out, but lately the sticker shock feel less like a barrier than the point. The price tags are festival markers, proof that what was once a tournament with posh accents has morphed into a cultural happening. In what seems like a remarkably short time, New York’s major has become less sporting event than aspirational brand.\n",
      "The final grand slam tournament of the season, which concludes Sunday with a mouth-watering men’s final between Jannik Sinner and Carlos Alcaraz, has never completely shied from its tony roots as part of the New York “social season”, but its latest evolution has taken it past a major sporting event into a festival economy. The sport is still there – highlight-reel shots, lung-busting rallies, after-midnight thrillers – but the real main draw are cocktails priced like small bond issues, influencer blocs in branded bucket hats and a dating show filmed courtside. The spectacle isn’t Sinner’s thunderbolt serve or Aryna Sabalenka’s power-baseline game but whether Chloe Malle is Anna Wintour’s plus-one or Kareem Rahma of Subway Takes posts his courtside selfie before or after the Honey Deuce runs dry. That libation, once just a cute themed lemonade and vodka in a souvenir cup, has mutated into an inflation-defying fetish object with its own merch line. Entire kiosks now sell Honey Deuce shirts and trucker hats in pastel colorways, so you can broadcast your melon-ball allegiance long after the hard-won hangover fades. It’s less a drink than a franchise, an alcoholic Funko Pop, proof that you didn’t just attend the Open: you consumed it, posted it, stacked it, wore it and recycled it into personal branding.\n",
      "The Open, known as the US national championships until 1968, has been staged every year since 1881, but its defining feature over the past decade or so has been sprawl: temporal, spatial, financial and, increasingly, attention-economical. Starting this year, the tournament expanded its footprint by starting on a Sunday rather than Monday, stretching the long-familiar 14-day format into 15, or effectively 20 if you count the controversial, purist-rankling mixed doubles event the week before. It is no longer just two weeks in late August and September straddling Labor Day, but a near-month-long residency in Flushing Meadows-Corona Park, calibrated to command not just your time and money but your feed. The prize fund for this year’s event climbed to an eye-watering $90m (£66.6m), the highest single-event purse in tennis history and a 20% jump from 2024. On the ground the United States Tennis Associaton has gone maximalist, rubber-stamping an $800m renovation of Arthur Ashe Stadium (separate from the recent three-year transformation that expanded the square-footage of the property). A $250m Player Performance Center is going up alongside it, kitted out to house 2,800 athletes and entourages, all part of the global arms race in sporting infrastructure. Meeting the luxe standard of Wimbledon is no longer enough; the pressure now is keeping up with Indian Wells and Madrid too.\n",
      "And in today’s climate the most significant currency is attention. Once upon a time the US Open existed in the collective imagination for two weeks; now it seeps across August and September, propped up by the USTA’s celebrity program, influencer activations and, yes, its new in-house dating show. Game, Set, Matchmaker – eight couples on first dates filmed around the grounds – is an explicit attempt to hijack the Love Island economy and make tennis trend on YouTube. It may scandalize traditionalists, but it’s entirely of a piece with a tournament that now produces as much reality TV as it does actual reality.\n",
      "Amanda Wight, the USTA’s director of international strategy, marketing and celebrity management, has become the impresario of this circuit. A soft-focus New York Times profile on Thursday detailed how she grew up in a tiny fishing village in South Australia, yet now knows exactly when Gigi Hadid’s SUV pulls up to the President’s Gate, slips a colored band on her wrist and escorts her past the phalanx of photogs on the blue carpet. In another life she might be curating a DJ lineup in the desert; now she’s booking Olivia Munn and John Mulaney into Ashe and ensuring Coco Gauff’s selfie with Simone Biles makes its way to Instagram. Celebrities don’t simply “drop by” anymore. They are recruited, logged and tracked like assets in a derivatives portfolio. The USTA enlists consultants to measure the engagement value of each famous face: how many posts, how many tags, how many millions of impressions. Those numbers determine whether you get another invite. The Open has built its own influencer exchange, trading futures contracts on Queen Latifah’s Instagram story. If you’ve been wondering why your feeds have become lousy with selfies snapped inside Ashe, often with an obligatory postscript like “thanks @americanexpress” or JPMorgan Chase or Emirates or some random make-up brand, it’s not an accident. From F1 paddocks to NBA front rows, modern sports all court star power. But in New York, the Open has turned it into something close to an art form. At times it feels less like a stop on the tennis tour than an aperitif to Fashion Week. The stands double as a runway, the sponsor suites as showrooms.\n",
      "Brands have always hovered around tennis, but now they’ve colonized every space across of the grounds. Rolex maintains its discreet, air-conditioned sanctuary where you can hear Novak Djokovic muttering to himself while politely slicing carrot cake topped with chocolate tennis balls. It feels like a Geneva watch fair disguised as a tennis match, a cool temple of precision where the $300,000 Daytona on a collector’s wrist matters as much as the scoreline. Just a few sections away, Graza Olive Oil commandeers a matrix of lower box seats packed with digital creators, influencers and fashion TikTokers. If Rolex is haute couture, Graza is streetwear – and both are equally stitched into the US Open’s cultural fabric. The levels of service for the VIP and VVIP sets inside Ashe have always caught my attention since my first year covering the Open in 2008 – there have always been different restaurants and hospitality experiences available exclusively to the various tiers of premium ticket holders – but the present-day setup has scaled it to entirely new late-capitalist levels.\n",
      "From a labor-studies perspective the irony is stark: ball kids sweating through 10-hour shifts, concession workers hustling food priced like fine dining, facilities staff removing garbage and re-stocking bathrooms, security guards scanning QR codes to keep the economy moving – all so celebrities can glide through a velvet-roped experience and post their carefully staged candids. The festival economy, whether in Coachella’s desert or Flushing Meadows’ heat, runs on the underpaid many serving the overexposed few. Yet sociologically, it’s more complicated. The Open has long prided and marketed itself as the “people’s slam”: No 7 subway rides, raucous night sessions going past 2am, the roar from Ashe echoing down Roosevelt Avenue when a match tips into a fifth set. That energy is still real and palpable, but it is increasingly filtered through fan performance and the ceaseless din of conversation during matches, especially inside the main two stadiums. Attending is no longer just about watching; it is about being seen watching. For a growing subset of fans, that means turning the Open into content. Taylor Fritz’s girlfriend Morgan Riddle, dubbed by the Times as “the most famous woman in men’s tennis”, has argued that “fangirls” drive the memes and the merch. Tommy Paul’s fiancée, the Dairy Boy founder Paige Lorenze, folds the action into her lifestyle vlogs. They’re not just spectators but producers, treating Ashe as both stadium and studio.\n",
      "Media theory would call this the triumph of the attention economy. What the USTA and its sponsors have achieved is a transformation of a two-week tournament into an endlessly scrollable feed. The result is a hybrid of competition and content, where the cutaways to Kevin Hart mugging from a suite or the Kylie Jenner-Timothée Chalamet hard launch are as important as the next break point. Anything popular becomes corporatized, as Chris Black, the podcaster and vibe consultant, puts it. The Open is no different.\n",
      "And yet the fans seem to love it. Attendance topped a million for the first time last year. Every person you follow on Instagram or TikTok seems to be there. For all the complaints about how grounds passes used to cost $60 (not that long ago), or how tickets are directly siphoned to the resale market and never hit the box office at face value (unconfirmed but probably true), and broader carping about how the regular fan is getting priced out, the uncomfortable truth is that admission could probably be even more expensive and the place would still sell out. We normies complain about the influencer zoo, then double-tap its highlights. It’s the same contradiction that keeps Coachella oversold and Art Basel hashtagged within an inch of its life. In that sense the Open is both groundbreaker and windsock: it’s setting the tone for how sport can be repackaged as culture while also reflecting the social economy we already live in.\n",
      "So is it bad? From one angle, yes: the commodification of everything, from caviar-flecked poultry to celebrity cameos, can be seen as crass or even obscene. But from another, it is simply the way we live now. Tennis is not immune to the elemental logics of virality, and if the price of cultural relevance is a $23 cocktail, a marked-up hoodie, a dating show on YouTube and a 20-day schedule, that may be the collateral of a deal we’ve already entered long ago. The ball is still in play, but somewhere between Queens and Indio, the US Open has become a festival of its own: less about forehands and backhands than about selfies, sponsorships and sprawl.\n",
      "### predicted class: rec.sport.baseball\n",
      "********************\n",
      "Donald Trump’s last trip to the US Open did not go as smoothly as his 2015 presidential campaign kickoff. Three months after that gold-plated escalator ride, Trump was booed upon arriving at the VIP entrance at Arthur Ashe Stadium and booed again when he was shown on the big screen during that night’s quarter-final match between Venus and Serena Williams. He hasn’t shown his face at Billie Jean National Tennis Center since.\n",
      "Trump, of course, would be first to say he had more pressing matters to attend to over the past eight years. Currently, he is facing four separate indictments related to his time as US president – not least 34 counts here in New York for alleged hush money payments to an adult film star. Perhaps Trump would never have sunk this low if he had stuck to his role as the US Open’s unofficial celebrity mascot instead of moving into politics. But that role also helped his late-stage career change. Nowadays, though, you would be hard-pressed to find any trace of the relationship around the US Open grounds. Trump doesn’t talk about his time here anymore. Neither does the USTA. It’s almost as if an affair that lasted nearly 40 years never happened.\n",
      "Trump and the US Open were once a love match in mutual attention-seeking and ego-stroking that history struggles to appreciate now. When they began seriously courting each other in the late 1970s, the US Open had just relocated from genteel country club surrounds in Forest Hills to its current digs here on the site of the 1964 World’s Fair, with the idea of evolving into a spectacle for more than just tennis. And Trump was a small-time local real estate developer with designs on outdoing his father. But thanks to a boom in quality American tennis players, the US Open mushroomed into a cultural force that eventually sucked in Fashion Week, the MTV’s Video Music Awards and other seasonal New York rites.\n",
      "All the while Trump looked like a poor-man’s vision of a rich tennis fan during his appearances at the US Open – braying into his cell phone well before the things were ubiquitous, signing dollar bills for rubberneckers, backhandedly shushing a young Barron and otherwise playing the role of Titus at the Colosseum.\n",
      "Trump was among the first in line for an Ashe Stadium luxury suite (valued at $200,000 for the duration of the tournament in the early 2000s), reportedly renting two at one point. (The USTA says the Trump Organization hasn’t signed another lease since giving up its box in 2017.) From that perch he became a bellwether of sorts, gossip columnists scrutinized his celebrity guests (American treasure Kevin Bacon, New England Patriots owner Robert Kraft, sitting president Bill Clinton) and fashion critics snarked at Trump’s habit of turning up in the same dark suit/bright tie ensemble like a comic-book villain – The Donald, as he was known back then. If sportswriters charted the wind with Trump’s hair, it’s because his presence was the surest indicator of a big story.\n",
      "Even the glamor girls Trump chose to decorate his suite with mark time. In 1998 it was Kylie Bax, a New Zealander who had one curious fan yelling: “Who’s the broad?” In 2003 it was Lisa Cant, an 18-year-old Canadian who was being touted as the next Kate Moss. For the all-Williams final in 2001, three days before the Twin Towers fell, Trump was joined in his suite by his ex-wife, Ivana, and future wife, Melania. Nineteen years later, a former model named Amy Dorris alleged to the Guardian that Trump sexually assaulted her outside the bathroom in his private suite at the tournament in 1997 when she was 24 (via his lawyers, Trump has strongly denied having ever harassed, abused or behaved improperly toward Dorris.)\n",
      "When Trump wasn’t lording over the US Open from on high, he could count on a prominent seat in the players’ box – next to then-Chris Evert beau Andy Mill for the American Sweetheart’s US Open farewell in 1989, beside Brooke Shields for Andre Agassi’s comeback tale in 1994, by himself for Caroline Wozniacki’s 2010 semi-final run (“There’s always a place for Mr Trump,” the Danish former No 1 said at the time.) Pat Rafter celebrated his US Open titles in 1997 and 1998 with Trump at the Park Avenue Country Club. A superstitious Andy Murray was a guest at Trump International Hotel for a stint after his 2012 stay there culminated in his first career major title (Murray has since mocked Trump on X, formerly Twitter. He is one of the few high-profile players to hit out at the former president).\n",
      "In her 1991 title victory speech a teenage Monica Seles thanked Trump – who was rumoured to have helped the world No 1 drop off the radar for a six-week stretch that saw her miss Wimbledon. “He was the one person that kind of said the whole two weeks that I could do it,” she said. The crowd had a go at them both. Trump never completely won them back. Boos often greeted his seemingly obligatory appearances on the big screen. Before long, the negativity became something to revel in.\n",
      "It should surprise no one that, given his long history of misogyny, Trump seemed particularly keen on mansplaining his way around women’s tennis. In a 2004 Inside Tennis interview he was particularly obsessed with just-crowned Wimbledon champion Maria Sharapova – doubting her business acumen in one breath (offering up “the right management”), doting on her like a prize horse the next (“her gait is magnificent … and those shoulders”) before concluding that her looks were what ultimately pushed her past Serena Williams in the Wimbledon final. “I think [Serena] looked across the court and said: ‘I’m playing against a supermodel.’ I think it had an impact.”\n",
      "But Trump was also hugely keen on the Williams sisters. The Philadelphia Inquirer’s match report from Venus’s 1997 US Open final clash against Martina Hingis makes a point of noting how Trump celebrated her biggest winners with an approving fist pump. In 2000 he volunteered to pay in excess of $1m to sponsor a Battle of the Sexes reboot pitting either Williams sister against John McEnroe, and seemed genuinely more interested in watching a repeat of history – this time, with teenagers beating up on a middle-aged man. Trump rang in the 2015 new year dancing with Serena at Mar-a-Lago. When an angry outburst at a lineswoman after a controversial foot fault call helped doom Serena in the 2009 semi-final, Trump didn’t hold back either. “[The lineswoman] had a smirk on her face and was being a wise guy,” he wrote in a post for the leadership section of the Trump University blog. “The backlash against Serena has been relentless, and she has been treated badly. She has apologized, and I think enough is enough.”\n",
      "Trump was unlike any other American tennis patron, one who in the late 1980s was as wont to support the USTA’s bid to keep the Open in Queens as push to move it back to Manhattan. At the dawn of Trump’s Apprentice fame in 2004, the USTA tapped him for a campaign to encourage participation in the sport. “If you don’t go to TennisWelcomeCenter.com,” Trump said in one endorsement video, “you’re fired.” A print version of the same advert had him sitting behind a desk holding a gold racket. The women’s tour wrangled him for their own promos, too. At the time the federation celebrated him as a youth ambassador of indeterminate value. Never mind that the man himself was pushing 60.\n",
      "In hindsight it’s a wonder Trump hung around the US Open for so long. When he ultimately did slink away, it was well overdue. He can draw plenty of big crowds on his own – ones that not only root for him, but help him attempt to reverse a presidential election. The US Open dominates New York’s cultural scene to the point of becoming a shrine for social climbers to practice conspicuous consumption – an all-American cultural symbol. The transactional relationship served its purpose for the tournament and for Trump. That both sides appear happy to stay apart speaks to just how drastically America’s course has diverged.\n",
      "### predicted class: talk.politics.misc\n",
      "********************\n",
      "The past few weeks have brought a torrent of bad news for those who care about CBS News – the home of the legendary Walter Cronkite and a great deal of investigative journalism over many decades.\n",
      "Most notably, the network’s parent company, Paramount Global, capitulated to the Trump administration, unnecessarily – and wimpily – settling a lawsuit by paying $16m, purportedly for a future presidential library.\n",
      "Trump had sued over a story on 60 Minutes, the network’s flagship program, claiming it was deceptively edited to favor his then-rival for the presidency, Kamala Harris. After the settlement was announced, Trump crowed that the network had “defrauded the American people” and was desperate to settle; he also claimed that another $20m in advertising and programming was also coming his way.\n",
      "Days later, another troubling sign. The network decided to dump The Late Show With Stephen Colbert, the top-rated show on late-night television, whose host has been relentlessly critical of Trump. Network bosses claimed the move was financial, since the show was losing money. But it wasn’t hard to connect the dots and see this as part of an all-out effort to appease the president.\n",
      "The Democratic senator Elizabeth Warren called for answers in a Variety op-ed, asking: “Are we sure that this wasn’t part of a wink-wink deal between the president and a giant corporation that needed something from his administration?”\n",
      "That “something” is federal clearance for an $8bn merger between Paramount and another giant media corporation, Skydance. (The latter company is doing its kowtowing part, promising to “evaluate any complaints of bias” at CBS News, appoint an ombudsman to keep watch, and ensure there are no diversity, equity and inclusion programs at Paramount. The proposed merger got approval on Thursday from the FCC, which means that it’s essentially a done deal.)\n",
      "Colbert’s on-air commentary on the settlement was brutal: “This kind of complicated financial settlement with a sitting government official has a technical name in legal circles. It’s ‘big, fat bribe’.” Could it be a complete coincidence that The Late Show was canceled three days later?\n",
      "Amid all this, one positive development this week shone through like a wan blade of light. A new executive producer for 60 Minutes – the top editorial role – got the nod. To the relief of many there, Tanya Simon is no outsider who might have been tapped to make the show more Trump-friendly.\n",
      "Simon has deep roots at the revered program – a 25-year veteran of 60 Minutes, she is also the daughter of the late CBS correspondent Bob Simon. She has been the acting executive producer since the previous executive producer, Bill Owens, resigned under pressure, saying he felt he no longer had the full editorial independence he had always enjoyed.\n",
      "Her appointment, of course, doesn’t mean no political pressure will be exerted from corporate bosses above her, who seem to be under Trump’s sway.\n",
      "“There is great fear about what comes next,” one CBS News staffer told CNN earlier this month. Simon’s appointment offers at least a modest measure of reassurance.\n",
      "She “understands what makes ‘60 minutes’ tick,” said the news division’s president, Tom Cibrowski, in a memo to staff. She’s also the first woman, in the show’s nearly six-decade history, to be at the helm.\n",
      "If the choice had been a right-leaning newcomer, it’s a good bet that top quality talent like Scott Pelley – a former chief White House correspondent and a former anchor of the CBS Evening News – would have quickly headed for the door.\n",
      "As for the future of CBS, once admired enough to be dubbed the Tiffany Network, the outlook is mixed.\n",
      "“I know that the C in CBS stands for Columbia, but … it ought to be called the Contradiction Broadcasting Network,” wrote Philadelphia Inquirer columnist Will Bunch.\n",
      "That’s always been true, he argued, given the bright journalistic legacy of Cronkite and Edward R Murrow along with some ugly chapters in the distant past. That includes the time when – under fire from the FBI director J Edgar Hoover in the late 1940s – the network demanded that all its employees sign a loyalty oath to the US government.\n",
      "When it comes to integrity, that history of contradiction is bad enough.\n",
      "Capitulation, though, is far worse. And given recent events, it’s easy to make the case that CBS – or, more accurately, its parent company – deserves that acronym even more.\n",
      "-\n",
      "Margaret Sullivan is a Guardian US columnist writing on media, politics and culture\n",
      "Comments (…)\n",
      "Sign in or create your Guardian account to join the discussion\n",
      "### predicted class: talk.politics.misc\n",
      "********************\n",
      "Donald Trump has reached a $16m settlement with Paramount, the parent of CBS News, over what he claimed was false editing of a pre-election interview with the Democratic candidate for president, Kamala Harris, in what is likely to be seen as a further example of capitulation by media companies hoping to smooth the waters with Trump.\n",
      "Trump had filed a $10bn lawsuit against the company in October, one of a string of legal actions against US media conglomerates over what the US president maintains was biased, incorrect or “fake” news reporting.\n",
      "In a late-night announcement, Paramount – which is preparing for a $8.4bn merger that requires approval from the the US Federal Communications Commission, headed by Trump loyalist Brendan Carr – said it would pay the sum to settle the suit.\n",
      "It said the money would be allocated, at Trump’s discretion, either to his future presidential library or to charitable causes, and not paid to Trump “directly or indirectly”.\n",
      "“The settlement does not include a statement of apology or regret,” the company statement added.\n",
      "A spokesperson for Trump’s legal team told the Wall Street Journal that the settlement was “another win for the American people as he, once again, holds the Fake News media accountable for their wrongdoing and deceit”.\n",
      "The lawsuit alleged that CBS, via its news show 60 Minutes, deceptively edited an interview with Harris – then the US vice-president as well as the Democratic presidential candidate – to “tip the scales in favor of the Democratic party” in the election. On the campaign trail last year, Trump threatened to revoke CBS’s broadcasting licence if elected.\n",
      "The lawsuit also alleged that CBS aired two versions of the interview in which Harris appeared to give different answers to the same question about the Israel-Hamas war. CBS said the lawsuit was “completely without merit” and had asked a judge to dismiss it.\n",
      "In an amended complaint filed in February, Trump increased his claim for damages to $20bn and added a claim that CBS’s editing of the interview violated the Texas Deceptive Trade Practices-Consumer Protection Act, which makes it illegal to use false, misleading or deceptive acts in commerce.\n",
      "The lawsuit was filed in Amarillo, Texas, a portion of a federal district court where the sole judge is a 2019 Trump appointee. The case entered mediation in April.\n",
      "The settlement includes an agreement that 60 Minutes would release transcripts of interviews with future US presidential candidates after they aired, subject to redactions as required for legal or national security concerns.\n",
      "The White House did not immediately respond to a request for comment. Edward A Paltzik, a lawyer representing Trump in the civil suit, could not be immediately reached for comment.\n",
      "Paltzik has previously said “real accountability for CBS and Paramount will ensure that the president is compensated for the harm done to him, and will deter the fake news from further distorting the facts to advance a partisan agenda”.\n",
      "The settlement comes as Paramount prepares for an $8.4bn merger with Skydance Media, which requires the approval of federal regulators at the FCC.\n",
      "But US and California lawmakers have said any settlement may violate bribery laws.\n",
      "“Paramount appears to be trying to settle a lawsuit that it has assessed as ‘completely without merit’,” the Democratic senators Elizabeth Warren, Bernie Sanders and Ron Wyden said in a May letter to Paramount’s chair, Shari Redstone.\n",
      "“Under the federal bribery statute, it is illegal to corruptly give anything of value to public officials to influence an official act.\n",
      "“If Paramount officials make these concessions in a quid pro quo arrangement to influence President Trump or other Administration officials, they may be breaking the law.”\n",
      "Sanders said it was “a dark day for independent journalism and freedom of the press – an essential part of our democracy. It is a victory for a president who is attempting to stifle dissent and undermine American democracy.”\n",
      "The settlement is the latest example of media corporate parent companies making concessions to Trump and the Trump administration, which frequently casts unfavorable coverage as “fake news”.\n",
      "On Tuesday, Trump and the homeland security secretary, Kristi Noem, threatened to sue CNN over its reporting on an app designed to help people avoid Immigration and Customs Enforcement agents, and over the reporting of a damage assessment on Iran’s nuclear facilities that was unfavorable to the administration’s claims.\n",
      "The settlement also comes after Meta Platforms, the Facebook and Instagram parent company, said on 29 January it had agreed to pay about $25m to settle a lawsuit by Trump over the company’s suspension of his accounts after the 6 January 2021 attack at the US Capitol.\n",
      "Paramount’s decision to settle the case – which has reportedly caused deep upset in the CBS newsroom – also follows ABC News agreeing to pay $15m to Trump to settle a defamation lawsuit over inaccurate comments by the anchor George Stephanopoulos that Trump had been found civilly liable for rape.\n",
      "### predicted class: talk.politics.misc\n",
      "********************\n"
     ]
    }
   ],
   "source": [
    "for article in articles[25:30]:\n",
    "    print(article[\"raw_text\"])\n",
    "    print(f\"### predicted class: {article['predicted']}\")\n",
    "    print(\"*\"*20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
